---
title: "Bayesian Regression for NFL"
author: "Kory D. Johnson"
date: 'Last Compiled `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    code_folding: show
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE,
               collapse = FALSE,
               comment = "",
               strip.white = TRUE,
               warning = FALSE,
               message = FALSE,
               out.width = "70%",
               fig.align = "center")
```

## Topic

This file creates some basic Regression models for nfl_yards.

## Set Up  {.tabset .tabset-fade}

### Packages/Files {-}

```{r}
library(tidyverse)
library(magrittr)
library(modelr)  # for cv
library(caret)
# devtools::install_github("korydjohnson/rai")
library(rai)
```

### Load Data {-}

```{r, cache=T}
loadData <- function(fileName = "train.csv", ...) {
  file = paste("../input", fileName, sep="/")
  data.table::fread(file, ...) %>% 
    as_tibble()
}
# "Rusher_Pos" removed
categorical = c("Down", "OffenseFormation", "Turf", "GameWeather")
theData = loadData("features_py.csv") %>% 
  mutate_at(vars(categorical), as.factor) %>% 
  select(-Rusher_Pos)  # Rusher_Pos causes cv problems
colnames(theData)
toExclude = which(theData$OffenseFormation == 5)  # only one observation
theData = slice(theData, -toExclude)
theResponse = loadData("response_py.csv") %>%
  slice(-toExclude) %>% 
  pull(Yards)
year = str_extract(theData$PlayId, "^.{4}")
theData = select(theData, -PlayId)
dim(theData); length(theResponse)
# unique(theData$OffenseFormation)
# theData
rangeY_true = seq(-99,99)  # modified for specific distributions
```



### Helper Functions {-}

```{r}
getProbs.norm = function(est, sd, rangeY, x=NULL, vB=NULL) {
  if (!is.null(x) && !is.null(vB)) {
    x = as.matrix(x, ncol=1)
    sd = sd*(1 + sqrt(t(x)%*%vB%*%x))
  }
  pnorm(rangeY, est, sd)
}

getProbs.pois = function(est, rangeY) {
  ppois(rangeY, est)
}

getProbsInd = function(est, rangeY) {
  rangeY >= est
}

getProbs.trans = function(est, muTrans=1.13, sdTrans=.216) {
  x = rangeY_true-est
  z = (sign(x)*abs(x)^(1/6) - muTrans)/sdTrans
  dens = dnorm(z)*abs(x)^(-5/6)/(6*sdTrans)
  infInd = which(is.infinite(dens))
  dens[is.infinite(dens)] = mean(c(dens[infInd+1], dens[infInd-1]))
  pdfT = c(0,diff(z))*dens
  pdf = pdfT/sum(pdfT)
  cumsum(pdf)
}
# dens
# ggplot(tibble(x, pdf)) +
#   geom_line(aes(x, pdf))
# getProbs.trans(5)

crps = function(probVec, y, rangeY) {
  Hy = (rangeY >= y)
  mean((probVec-Hy)^2)
}
```

Post process prob estimates
```{r}
rescaleProbs = function(probs, lims = c(-5,25), distGoal=NULL) {
  lower = which(rangeY_true==lims[1])
  if (!is.null(distGoal)) {
    lims[2] = min(distGoal, lims[2])
  }
  upper = which(rangeY_true==lims[2])
  relProbs = probs[lower:upper]
  if (max(relProbs)==0) {
    probs
  } else {
    c(rep(0, lower-1), relProbs/max(relProbs), rep(1, 199-upper))
  }
}
```

Plot Individual Predictions
```{r}
plotProbEst = function(probs, y, rangeY, pred) {
  Hy = as.integer(rangeY >= y)
  tibble(probs, Hy, yards = rangeY_true) %>% 
    gather(fnc, value, probs, Hy) %>% 
    ggplot() +
    geom_line(aes(yards, value, color=fnc)) +
    xlim(c(-20,30)) +
    labs(title = paste0("Distribution Estimate for prediction ", pred))
}
```

### Recalibration {-}

Create Data Set
```{r}
# distList = distPreds$probsNorm_hom
# map_dbl(distList, ~.x[rangeY_true == .y])
recalibrateCdf = function(distList, response, rangeY) {
  FtYt = map2_dbl(distList, response, ~.x[rangeY == .y])
  Phat_FtYt = map_dbl(FtYt, ~mean(FtYt <= .x))
  isoMod = as.stepfun(isoreg(FtYt, Phat_FtYt))
  class(isoMod) = c("isoStep", class(isoMod))
  isoMod
  # map(distList, ~mod(.x))
}

predict.isoStep = function(object, newdata) {
  object(newdata)
}
```

### CV Functions {-}

Just to compare. Will use CV to get an estimate of performance before uploading to cloud.
```{r}
predictCV = function(theResponse, theData, modelFnc, rangeY, k=5) {
  modFnc = function(data) {
    modelFnc(data[, -1, drop=F], data[, 1])
  }
  sdErr = function(modelObject) {
    if (is.null(summary(modelObject)$sigma)) {
      summary(modelObject$model)$sigma
    } else {
      summary(modelObject)$sigma
    }
  }
  
  theResponse = as.matrix(theResponse)
  data = data.frame(y=theResponse, theData)
  if (any(map_lgl(data, is.factor))) {
    folds = data %>% crossv_kfold_stratified(k=k)
  } else {
    folds = data %>% crossv_kfold(k = k)
  }
  # data %>% crossv_kfold(k = k) %>% 
  probs = folds %>% 
    mutate(
      mod = map(train, ~modFnc(as.data.frame(.))),
      pred_tr = map2(mod, train, ~ predict(.x, as.data.frame(.y))),
      pred_te = map2(mod, test, ~ predict(.x, as.data.frame(.y))),
      sd = map_dbl(mod, ~ sdErr(.)),
      probs_tr = map(pred_tr, ~map(.x, getProbs.norm, sd, rangeY=rangeY)),
      probs_te = map(pred_te, ~map(.x, getProbs.norm, sd, rangeY=rangeY)),
      isoMod = map2(probs_tr, train, ~recalibrateCdf(.x, as.data.frame(.y)$y, rangeY)),
      probs_te_re = map2(probs_te, isoMod, ~map(.x, predict, object=.y))
    ) %>%
    select(probs_te, probs_te_re) %>% 
    unnest() %>% 
    mutate_all(~map2_dbl(.x, theResponse, crps, rangeY=rangeY)) %>% 
    summarise_all(mean)
}

errorOOS = function(theResponse, theData, fncs, rangeY, k=5) {
  map(fncs, ~ predictCV(theResponse, theData, ., rangeY, k))
}
```

stratified cv
```{r}
crossv_kfold_stratified = function(data, k, groups=NULL) {
  if (is.null(groups)) {
    groups = colnames(data)[map_lgl(data, is.factor)]
  }
  # get folds; uses caret
  folds = data %>% 
    select(!!!eval(groups)) %>% 
    unite(categories) %>%
    pull(categories) %>% 
    createFolds(k = k)
  # convert to resample object for use with modelr
  tibble(folds) %>% 
    mutate(train = map(folds, ~resample(data, (1:nrow(data))[-.])),
           test = map(folds, ~resample(data, (1:nrow(data))[.])),
           id = 1:length(folds)) %>% 
    select(-folds)
}
# groups = colnames(theData)[map_lgl(theData, is.factor)]
# groups
# for (col in groups) {
#   for (fold in folds) {
#       print(table(theData[fold, col]))
#   }
# }
# folds <- createFolds(theData$Down, k = 5, list=F)
# table(folds)
```

### Modeling Functions {-}

LM
```{r}
fitLM = function(theData, theResponse) {
  lm(theResponse ~ ., data=theData)
}
fitMean = function(theData, theResponse) {
  lm(theResponse ~ ., data=theData)
}
fitPoly = function(theData, theResponse) {
  
}
```

Poisson Reg
```{r}
runPoisReg = function(theData, theResponse) {
  glm(theResponse ~., family = "poisson", data = theData)
}
```


# Marginal Models

## Beta Dist to Normal

As the base model was a marginal MLE of yards, see shape of predicted distribution.

```{r}
a = 112.75760456
b = 103.6066858
x = seq(0, 198)/198
beta = dbeta(x, a, b)
dfBeta = tibble(x, beta)
dfBeta %>% 
  filter(beta > .001) %>% 
  ggplot() +
  geom_line(aes(x*199-99, beta))
```

Short answer: yeah, normal.
```{r}
mu = a/(a+b)
sig = sqrt(a*b/((a+b)^2*(a+b+1)))
dfBeta %<>%
  mutate(normal = dnorm(x, mu, sig))
dfBeta %>% 
  gather("dist", "density", beta, normal) %>% 
  filter(density > .01) %>% 
  ggplot() +
  geom_line(aes(x, density, color=dist))
```


## Normal

MLE unadjusted
```{r}
(pred = mean(theResponse))
(sd = sd(theResponse))
tibble(theResponse) %>% 
  mutate(
    probEst = map2(pred, sd, getProbs.norm, rangeY=rangeY_true),
    crps = map2_dbl(probEst, theResponse, crps, rangeY=rangeY_true)
  ) %>% 
  summarise(crps = mean(crps))
```

MLE transformed
```{r}
theResponse2 = log(pmax(theResponse + 15, 1))
rangeY_norm = log(pmax(rangeY_true + 15, 1))
(pred = mean(theResponse2))
(sd = sd(theResponse2))
tibble(theResponse2) %>% 
  mutate(
    probEst = map2(pred, sd, getProbs.norm),
    crps = map2_dbl(probEst, theResponse2, crps, rangeY_norm)
  ) %>% 
  summarise(crps = mean(crps))

probs = getProbsInd(pred, rangeY_norm)
mean(map_dbl(theResponse2, crps, probVec=probs, rangeY=rangeY_norm))

probs = getProbsInd(pred, rangeY_norm)
for (i in 1:5) {
  print(plotProbEst(probs, theResponse2[i], rangeY_norm))
}
```

idk why normal seems to do poorly even though the estimated beta distribution looks essentially normal. Check same code for beta.

beta
```{r}
getProbsBeta = function(a,b) {
  x = seq(0, 198)/198
  pbeta(x, a, b)
}

a = 112.75760456
b = 103.6066858
x = seq(0, 198)/198
beta = pbeta(x, a, b)
tibble(x, beta, pred = x*198-99)
tibble(theResponse) %>% 
  mutate(
    probEst = map2(a, b, getProbsBeta),
    crps = map2_dbl(probEst, theResponse, crps, rangeY=seq(-99,99))
  ) %>% 
  summarise(crps = mean(crps))
```

Hm, from this, beta seems to be on the same scale as normal, which makes sense. Checking with Danijel to see if he gets similar answers on training data. It is far higher than the results we get on the test data.

Data Issue. All good now.

# LM

transformations
```{r}
theResponse2 = pmax(theResponse + 14,0)^(1/2)
theResponse2 = pmax(theResponse + 14,0)
qqnorm(theResponse2)
theResponse2 = log(pmax(theResponse + 14, 1))
rangeY_norm = log(pmax(rangeY_true + 14, 1))
theData2 = model.matrix(~.,data=theData)
vBeta = solve(crossprod(theData2))
qqnorm(theResponse2)
tibble(response = theResponse2) %>% 
  ggplot() + 
  geom_density(aes(response))
```

In-sample
```{r}
lmOut = lm(theResponse2~., data=theData)
# plot(lmOut)
pred = lmOut$fitted.values

distPreds = 
  tibble(pred = lmOut$fitted.values, response = theResponse2,
         data = split(theData2, row(theData2))) %>%
  mutate(probsInd = map(pred, getProbsInd, rangeY=rangeY_norm),
         probsNorm_hom = map(pred, getProbs.norm, rangeY=rangeY_norm, sd=summary(lmOut)$sigma),
         probsNorm_hom2 = map(pred, getProbs.norm, rangeY=rangeY_norm, sd=.2))
         # probsNorm_het = map2(pred, data, getProbs.norm,
         #                      rangeY=rangeY, sd=.2, vB=vBeta))
distRecal = distPreds %>% 
  mutate_at(vars(starts_with("probs")), recalibrateCdf, theResponse2, rangeY_norm)

distPreds %>%
  # mutate_at(vars(starts_with("probs")), ~map(., rescaleProbs)) %>%
  mutate_at(vars(starts_with("probs")), ~map2_dbl(., response, crps, rangeY=rangeY_norm)) %>%
  summarise_at(vars(starts_with("probs")), mean)
distRecal %>%
  # mutate_at(vars(starts_with("probs")), ~map(., rescaleProbs)) %>% 
  mutate_at(vars(starts_with("probs")), ~map2_dbl(., response, crps, rangeY=rangeY_norm)) %>%
  summarise_at(vars(starts_with("probs")), mean)
```
pure quadratic model got .01478 online; 2018 data 0.01482
in samp gets 0.01317

CV estimates
```{r}
theResponse2 = log(pmax(theResponse + 16, 1))
rangeY_norm = log(pmax(rangeY_true + 16, 1))
modelFnc = fitLM
(out = predictCV(theResponse2, theData, modelFnc, rangeY=rangeY_norm))
```

Looking at some estimates.

```{r}
# probs = getProbsInd(pred, rangeY)
for (i in 1:5) {
  x = as.matrix(theData2[i,], ncol=1)
  # print(sqrt(t(x)%*%vBeta%*%x))
  sd = summary(lmOut)$sigma
  probs = getProbs.norm(pred[i], sd, rangeY_norm)
  print(plotProbEst(probs, theResponse2[i], rangeY_norm, pred[i]))
}
# summary(lmOut)
```

See Predictions on Test Data
```{r}
theDataTe = loadData("featuresTest_py.csv") %>% 
  select(-toRemove) %>% 
  mutate_at(vars(categorical), as.factor)
predTe = predict(lmOut, data=theDataTe)
tibble(pred, predTe) %>% 
  gather("sample", "value") %>% 
  ggplot() +
  geom_density(aes(value, color=sample, linetype=sample))
```

## Compare Models
```{r}
theResponse2 = log(pmax(theResponse + 16, 1))
rangeY_norm = log(pmax(rangeY_true + 16, 1))
functions = list(fitLM, fitMean, rai)
errorOOS(theResponse2, theData, functions, rangeY_norm)
```

## Fewer Features
Sig Features: 
Distance, OffenseFormation, LineOfScrimmage,
Rusher_Gap_AveSpaceD, Rusher_ADef, Rusher_Acc, Rusher_DistDef, Rusher_DistDefMean, Rusher_DistLOS, Rusher_Gap_DistDirLOS, Rusher_Gap_NPlayersD, Rusher_Gap_Radius,
Rusher_Gap_TeamRatioT, Rusher_SDef, Rusher_SpeedX, Rusher_SpeedY, Team_DefDistLOS, Team_DefXStd, Team_OffDistLOS

```{r}
theData2 = theData %>% 
  select(Distance, OffenseFormation, LineOfScrimmage,
         Rusher_Gap_AveSpaceD, Rusher_ADef, Rusher_Acc, Rusher_DistDef, Rusher_DistDefMean,
         Rusher_DistLOS, Rusher_Gap_DistDirLOS, Rusher_Gap_NPlayersD, Rusher_Gap_Radius,
         Rusher_Gap_TeamRatioT, Rusher_SDef, Rusher_SpeedX, Rusher_SpeedY, Team_DefDistLOS,
         Team_DefXStd, Team_OffDistLOS) %>% 
  mutate(OffenseFormation = as.factor(OffenseFormation %in% c(1,4)))
theData2
errorOOS(theResponse2, theData2, functions, rangeY_norm)
# out = predictCV(theResponse2[year=="2018"], theData2[year=="2018",], fitMean, rangeY_norm)
```


## RAI

```{r}
modelFnc = rai
modelFnc = partial(rai, alpha=.1, startDeg = 1)
out = predictCV(theResponse2, theData, modelFnc, rangeY=rangeY_norm)
out
distPreds = 
  tibble(pred = rai_out$model$fitted.values, response = theResponse2,
         data = split(theData, row(theData))) %>%
  mutate(probsInd = map(pred, getProbsInd, rangeY=rangeY_norm),
         probsNorm_hom = map(pred, getProbs.norm, rangeY=rangeY_norm,
                             sd=summary(rai_out$model)$sigma),
         probsNorm_hom2 = map(pred, getProbs.norm, rangeY=rangeY_norm, sd=.2)) %>% 
  mutate_at(vars(starts_with("probs")), ~map2_dbl(., response, crps, rangeY=rangeY_norm))
distPreds %>% 
  summarise_at(vars(starts_with("probs")), mean)
```

Making predictions
```{r}
rai_out = rai(theData, theResponse2, alpha=.1)
mod = rai_out$model
predict(mod, data.frame(model.matrix(~., data=theData)))
```

# Poisson Regression

Fit seems quite good; when get error just from 

```{r}
theResponse2 = pmax(theResponse+14, 0)
rangeY_pois = pmax(rangeY_true+14, 0)

qqnorm(pmax(theResponse+14, 0))
qqnorm(pmax(theResponse+14, 0)^(1/2))
tibble(response = theResponse2) %>%
  ggplot() + 
  geom_density(aes(response))

glmOut = glm(theResponse2^(1/2) ~., family = "poisson", data = theData)
pred = glmOut$fitted.values^2

distPreds = 
  tibble(
    pred = pred,
    response = theResponse2,
    distGoal = 100-theData$LineOfScrimmage
  ) %>%
  mutate(
    probsInd = map(pred, getProbsInd, rangeY=rangeY_pois),
    probsPois = map(pred, getProbs.pois, rangeY=rangeY_pois),
    probsPois_s1 = map(probsPois, rescaleProbs),
    probsPois_s2 = map2(probsPois, distGoal, ~rescaleProbs(.x, distGoal=.y)),
    probsTrans = map(pred, getProbs.trans),
    probsTrans_s1 = map(probsTrans, rescaleProbs),
    probsTrans_s2 = map2(probsTrans, distGoal, ~rescaleProbs(.x, distGoal=.y))
  )
distPreds %>%
  mutate_at(vars(starts_with("probs")), ~map2_dbl(., response, crps, rangeY=rangeY_pois)) %>% 
  summarise_at(vars(starts_with("probs")), mean)
```

Plotting
```{r}
diffs = tibble(pred, theResponse2) %>% 
  mutate(diff = theResponse2-pred)
ggplot(diffs) +
  geom_density(aes(diff))
ggplot(diffs) +
  geom_density(aes(diff^(1/6)))
ggplot(diffs) +
  geom_density(aes(abs(diff)^(1/6)))

diffs %>% 
  summarize(mean = mean(abs(diff)^(1/6)),
          sd = sd(abs(diff)^(1/6)))

qqnorm(diffs$diff^(1/6))
summary(diffs$diff)

probs = getProbsInd(pred[1], rangeY_pois)
plotProbEst(probs, theResponse2[1], rangeY_pois)
col = "probsInd"
col = "probsPois_s1"
col = "probsPois_s2"
for (i in 1:5) {
  probs = distPreds[[col]][[i]]
  print(plotProbEst(probs, theResponse2[i], rangeY_pois))
}
```


# Survival Models

```{r}
library(survival)
shift = 4; maximum = 21
theResponse2 = pmax(pmin(theResponse + 4, maximum+4), 1)
censored = theResponse + 4 > maximum+4
surv_object <- Surv(theResponse, censored)
mod = survreg(surv_object~., data=theData, dist="gaussian")

coxPH <- coxph(surv_object ~ ., data = theData)
exp(predict(coxPH, type="risk"))
predict(coxPH, type="risk")
predict(coxPH, type="expected")
mod
names(summary(mod))
test = theData[1:5, ]
predict(mod, test, se.fit=T)
head(theResponse2)
```
