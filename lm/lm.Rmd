---
title: "Bayesian Regression for NFL"
author: "Kory D. Johnson"
date: 'Last Compiled `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    code_folding: show
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE,
               collapse = FALSE,
               comment = "",
               strip.white = TRUE,
               warning = FALSE,
               message = FALSE,
               out.width = "70%",
               fig.align = "center")
```

## Topic

This file creates some basic Regression models for nfl_yards.

## Set Up  {.tabset .tabset-fade}

### Packages/Files {-}

```{r}
library(tidyverse)
library(magrittr)
library(modelr)  # for cv
library(caret)
# devtools::install_github("korydjohnson/rai")
library(rai)
```

### Load Data {-}

```{r, cache=T}
loadData <- function(fileName = "train.csv", ...) {
  file = paste("../input", fileName, sep="/")
  data.table::fread(file, ...) %>% 
    as_tibble()
}
categorical = c("Down", "OffenseFormation", "Turf", "GameWeather", "Rusher_Pos")
toRemove = c(1:12, 14:16, 21:28, 33)
theData = loadData("features_py.csv") %>% 
  select(-toRemove) %>% 
  mutate_at(vars(categorical), as.factor)
# dim(model.matrix(~., data=theData))
# dim(model.matrix(~.^2, data=theData))
theResponse = loadData("response_py.csv") %>% 
  pull(Yards)
dim(theData); length(theResponse)
# theData
```



### Helper Functions {-}

```{r}
getProbs.norm = function(est, sd, rangeY=NULL, x=NULL, vB=NULL) {
  if (is.null(rangeY)) {
    rangeY = log(pmax(seq(-99,99) + 15, 0))
  }
  if (!is.null(x) && !is.null(vB)) {
    x = as.matrix(x, ncol=1)
    sd = sd*(1 + sqrt(t(x)%*%vB%*%x))
  }
  pnorm(rangeY, est, sd)
}

getProbs.pois = function(est, rangeY=NULL) {
  if (is.null(rangeY)) {
    rangeY_pois_rel = (pmax(seq(-14,99) + 14, 0))^(1/4)
    rangeY = c(rep(-1, 199-length(rangeY_pois_rel)), rangeY_pois_rel)
  }
  ppois(rangeY, est)
}

getProbsInd = function(est, rangeY) {
  rangeY >= est
}

crps = function(probVec, y, rangeY) {
  Hy = (rangeY >= y)
  mean((probVec-Hy)^2)
}
```

Post process prob estimates
```{r}
rescaleProbs = function(probs, lims = c(-5,25)) {
  rangeY = seq(-99,99)
  lower = which(rangeY==lims[1])
  upper = which(rangeY==lims[2])
  relProbs = probs[lower:upper]
  if (max(relProbs)==0) {
    probs
  } else {
    c(rep(0, lower-1), relProbs/max(relProbs), rep(1, 199-upper))
  }
}
```

Plot Individual Predictions
```{r}
plotProbEst = function(probs, y, rangeY) {
  Hy = as.integer(rangeY >= y)
  tibble(probs, Hy, yards = seq(-99,99)) %>% 
    gather(fnc, value, probs, Hy) %>% 
    ggplot() +
    geom_line(aes(yards, value, color=fnc))
}
```

### CV Functions {-}

Just to compare. Will use CV to get an estimate of performance before uploading to cloud.
```{r}
predictCV = function(theResponse, theData, modelFnc, k=5) {
  if (any(grepl("runAuction", capture.output(modelFnc)))) {
    modFnc = function(data) {
      # to send original data; modified it below for use in OOS prediction
      theDataO = apply(data[, -1, drop=F], 2, function(col) col^(1/startDeg))
      modelFnc(theDataO, data[, 1])$model
    }
    theData = model.matrix(~. - 1, data=as.data.frame(theData))
    startDeg = formals(modelFnc)$startDeg
    theData = apply(theData, 2, function(col) col^startDeg)  # modify for OOS
    cat("rai", startDeg, ";\n")
  } else {
    cat("other; \n")
    modFnc = function(data) {
      modelFnc(data[, -1, drop=F], data[, 1])
    }
  }
  
  theResponse = as.matrix(theResponse)
  data = data.frame(y=theResponse, theData)
  data %>% crossv_kfold(k = k) %>% 
    mutate(
      model = map(train, ~modFnc(as.data.frame(.))),
      predicted = map2(model, test, ~ add_predictions(as.data.frame(.y), .x)),
      sd = map_dbl(model, ~ summary(.)$sigma)
    ) %>%
    select(predicted, sd) %>% 
    unnest(predicted) %>% 
    mutate(
      probEst = map2(pred, sd, getProbs),
      crps = map2_dbl(probEst, y, crps)
    ) %>% 
    summarise(crps = mean(crps))
}

errorOOS = function(theResponse, theData, fncs, k=5) {
  map(fncs, ~ predictCV(theResponse, theData, ., k))
}
```

### Modeling Functions {-}

LM
```{r}
runLM = function(theData, theResponse) {
  lm(theResponse ~ ., data=theData)
}
```

Poisson Reg
```{r}
runPoisReg = function(theData, theResponse) {
  glm(theResponse ~., family = "poisson", data = theData)
}
```


# Marginal Models

## Beta Dist to Normal

As the base model was a marginal MLE of yards, see shape of predicted distribution.

```{r}
a = 112.75760456
b = 103.6066858
x = seq(0, 198)/198
beta = dbeta(x, a, b)
dfBeta = tibble(x, beta)
dfBeta %>% 
  filter(beta > .001) %>% 
  ggplot() +
  geom_line(aes(x*199-99, beta))
```

Short answer: yeah, normal.
```{r}
mu = a/(a+b)
sig = sqrt(a*b/((a+b)^2*(a+b+1)))
dfBeta %<>%
  mutate(normal = dnorm(x, mu, sig))
dfBeta %>% 
  gather("dist", "density", beta, normal) %>% 
  filter(density > .01) %>% 
  ggplot() +
  geom_line(aes(x, density, color=dist))
```


## Normal

MLE unadjusted
```{r}
theResponse = dfSub$Yards
(pred = mean(theResponse))
(sd = sd(theResponse))
tibble(theResponse) %>% 
  mutate(
    probEst = map2(pred, sd, getProbs, rangeY=seq(-99,99)),
    crps = map2_dbl(probEst, theResponse, crps, rangeY=seq(-99,99))
  ) %>% 
  summarise(crps = mean(crps))
```

MLE transformed
```{r}
theResponse2 = log(pmax(theResponse + 15, 0))
(pred = mean(theResponse2))
(sd = sd(theResponse2))
tibble(theResponse2) %>% 
  mutate(
    probEst = map2(pred, sd, getProbs),
    crps = map2_dbl(probEst, theResponse2, crps)
  ) %>% 
  summarise(crps = mean(crps))

rangeY = log(pmax(seq(-99,99) + 15, 0))
probs = getProbsInd(pred, rangeY)
mean(map_dbl(theResponse2, crps, probVec=probs, rangeY=rangeY))

probs = getProbsInd(pred, rangeY)
for (i in 1:5) {
  print(plotProbEst(probs, theResponse2[i], rangeY))
}
```

idk why normal seems to do poorly even though the estimated beta distribution looks essentially normal. Check same code for beta.

beta
```{r}
getProbsBeta = function(a,b) {
  x = seq(0, 198)/198
  pbeta(x, a, b)
}
theResponse = dfSub$Yards

a = 112.75760456
b = 103.6066858
x = seq(0, 198)/198
beta = pbeta(x, a, b)
tibble(x, beta, pred = x*198-99)
tibble(theResponse) %>% 
  mutate(
    probEst = map2(a, b, getProbsBeta),
    crps = map2_dbl(probEst, theResponse, crps, rangeY=seq(-99,99))
  ) %>% 
  summarise(crps = mean(crps))
```

Hm, from this, beta seems to be on the same scale as normal, which makes sense. Checking with Danijel to see if he gets similar answers on training data. It is far higher than the results we get on the test data.

Data Issue. All good now.

## LM
```{r}
theResponse2 = log(pmax(theResponse + 15, 0))
theData2 = model.matrix(~.,data=theData)
vBeta = solve(crossprod(theData2))
qqnorm(theResponse2)
tibble(response = theResponse2) %>% 
  ggplot() + 
  geom_density(aes(response))
lmOut = lm(theResponse2~.^2, data=theData)
rangeY = log(pmax(seq(-99,99) + 15, 0))
pred = lmOut$fitted.values

distPreds = 
  tibble(pred = lmOut$fitted.values, response = theResponse2,
         data = split(theData2, row(theData2))) %>%
  mutate(probsInd = map(pred, getProbsInd, rangeY=rangeY),
         probsNorm_hom = map(pred, getProbs.norm, rangeY=rangeY, sd=summary(lmOut)$sigma),
         probsNorm_hom2 = map(pred, getProbs.norm, rangeY=rangeY, sd=.2),
         probsNorm_het = map2(pred, data, getProbs.norm, 
                              rangeY=rangeY, sd=.2, vB=vBeta)) %>% 
  # mutate_at(vars(starts_with("probs")), ~map(., rescaleProbs)) %>% 
  mutate_at(vars(starts_with("probs")), ~map2_dbl(., response, crps, rangeY=rangeY))
distPreds %>% 
  summarise_at(vars(starts_with("probs")), mean)
```


Looking at some estimates
```{r}
# probs = getProbsInd(pred, rangeY)
for (i in 1:5) {
  x = as.matrix(theData2[i,], ncol=1)
  print(sqrt(t(x)%*%vBeta%*%x))
  sd = summary(lmOut)$sigma
  probs = getProbs.norm(pred[i], sd)
  print(plotProbEst(probs, theResponse2[i], rangeY))
}
```

See Predictions on Test Data
```{r}
theDataTe = loadData("featuresTest_py.csv") %>% 
  select(-toRemove) %>% 
  mutate_at(vars(categorical), as.factor)
predTe = predict(lmOut, data=theDataTe)
tibble(pred, predTe) %>% 
  gather("sample", "value") %>% 
  ggplot() +
  geom_density(aes(value, color=sample, linetype=sample))
```

# CV and Compute Error

Test, not in code block just to prevent running via "Run All Chunks Above"

df = loadData("trainClean.csv")
dfSub = df %>% 
  distinct(PlayId, .keep_all = T) %>%
  # select(Yards, Distance, Down) %>% 
  select(Yards, Distance, Down, YardLine, NflIdRusher, OffenseFormation,
    OffensePersonnel, DefendersInTheBox, DefensePersonnel) %>%
  mutate(
    Down = as.factor(Down),
    NflIdRusher = as.factor(NflIdRusher)
  )

theResponse = log(pmax(dfSub$Yards + 15, 0))
theData = select(dfSub, -Yards)
# theData = data.frame(rep(1, length(theResponse)))
modelFnc = runLM
modelFnc = rai
predictCV(theResponse, theData, modelFnc)
errorOOS(theResponse, theData, list("rai"=rai, "lm"=runLM))

## Running Linear Models

```{r}
theResponse2 = log(pmax(theResponse + 15, 0))
covariates = c("Quarter", "PossessionTeam", "Down", "Distance", "OffenseFormation",
  "DefendersInTheBox", "Turf", "GameWeather", "DistanceToGoal", "DistanceToLOS",
  "RusherInfo_Acc", "RusherInfo_DistDef", "RusherInfo_DistLOS",
  "RusherInfo_Pos", "RusherInfo_SpeedX", "RusherInfo_SpeedY" )
categorical = c("Quarter", "PossessionTeam", "Down", "OffenseFormation", "Turf", "GameWeather", "RusherInfo_Pos")
theData2 = theData %>% 
  select(covariates) %>% 
  mutate_at(vars(categorical), as.factor)
modelFnc = rai
# modelFnc = runLM
out = predictCV(theResponse2, theData2, modelFnc)
# errorOOS(theResponse, theData2, list("rai"=rai, "lm"=runLM))
```

# RAI caret

```{r}
rai_caret = list(library = "rai",
                 type = "Regression",
                 prob = NULL)
# subsampling, start parameter, alpha
rai_caret$parameters = data.frame(parameter = c("alpha", "startDeg"),
                                  class = rep("numeric", 2),
                                  label = c("alpha", "startDeg"))
rai_caret$grid = function(x, y, len=NULL, search = "grid") {
  expand.grid(alpha = c(.01, seq(.05,.25,.05)),
              startDeg = c(1, .5, 1/3))
} 
rai_caret$fit = function(x, y, wts=NULL, param, lev=NULL, 
                         last, weights, classProbs, ...) {
  rai::rai(theData = x, theResponse = y, alpha = param$alpha, ...)
}
rai_caret$predict = function(modelFit, newdata, preProc = NULL, 
                             submodels = NULL) {
  rai::predict.rai(modelFit, newdata) 
}
rai_caret$sort = function(x) x[order(rev(x$startDeg), x$alpha),]
rai_caret$predictors = function(modelFit) {
  modelFit$features
}
```

Testing the Model
```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 5, ## 10-fold CV...
                           repeats = 5)  ## repeated ten times
# train(x=theData, y=theResponse, method=rai_caret, trControl = fitControl)
```

Adding the loop for sequential parameters (in this case, alpha). Will require a good amount of processing from `rai$summary`. This also requires a more general predict command.

```{r}
rai_caret$loop = function(grid) {
  deg <- unique(grid$startDeg)
  loop <- data.frame(startDeg = deg)
  loop$alpha <- NA
  submodels <- vector(mode = "list", length = length(deg))
  for(i in seq(along = deg)) {
    np <- grid[grid$startDeg == deg[i],"alpha"]
    loop$alpha[loop$startDeg == deg[i]] <- np[which.max(np)]
    submodels[[i]] <- data.frame(alpha = np[-which.max(np)])
  }
  list(loop = loop, submodels = submodels)
}
rai_caret$predict = function(modelFit, newdata, preProc = NULL, 
                             submodels = NULL) {
  out = predict(modelFit, newdata) 
  if(!is.null(submodels)) {
    out = list(out)
    for(j in seq(along = submodels$alpha)) {
      out[[j+1]] <- predict(modelFit, newdata, alpha = submodels$alpha[j])
    }
  }
  out  
}
```

Testing
```{r}
train(x=theData2, y=theResponse2, method=rai_caret, trControl = fitControl)
```

Performance
```{r}
tibble(theResponse) %>% 
  mutate(
    probEst = map2(pred, sd, getProbs),
    crps = map2_dbl(probEst, theResponse, crps)
  ) %>% 
  summarise(crps = mean(crps))
```

# Poisson Regression

Fit seems quite good; when get error just from 

```{r}
theResponse2 = (theResponse+14)^(1/4) 
qqnorm(theResponse2)
tibble(response = theResponse2) %>% 
  ggplot() + 
  geom_density(aes(response))

rangeY_pois_rel = (pmax(seq(-14,99) + 14, 0))^(1/4)
rangeY = c(rep(-1, 199-length(rangeY_pois_rel)), rangeY_pois_rel)
glmOut = glm(theResponse2 ~., family = "poisson", data = theData)
pred = glmOut$fitted.values
mean(map2_dbl(pred, theResponse2, crps.pois))
tibble(pred = pred, response = theResponse2) %>% 
  mutate(probs = map(pred, getProbsInd, rangeY=rangeY),
         err = map2_dbl(probs, response, crps, rangeY=rangeY)) %>% 
  summarise(err = mean(err))

tibble(pred, theResponse2) %>% 
  mutate(diff = theResponse2-pred) %>% 
  ggplot() +
  geom_density(aes(diff))


probs = getProbsInd(est, rangeY)
rangeY_pois = (pmax(seq(-99,99) + 14, 0))^(1/4)
plotProbEst(probs, y, rangeY_pois)
probs = getProbsInd(pred, rangeY)
for (i in 1:5) {
  probs = getProbsInd(pred[i], rangeY)
  print(plotProbEst(probs, theResponse2[i], rangeY))
}
```